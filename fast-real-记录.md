## Fast Real 记录

### 2019/2/26

> 今日计划

* 修改默认配置参数为从yml文件中读取
* 修改制作tf-record文件数据代码，重新制作数据集



> 修改默认参数为从yml文件中读取

* 鱼和熊掌，两者不可兼得
  * 若是使用yml文件，可能需要拆分现有的config和yml文件中的参数
  * 故部分参数由config提供，部分参数由yml提供比较好
* training这个参数，测试和训练都要用到，那么两个地方都有比较好；但是用于训练的yml文件为True，用于测试的config为False
* 在yml中报错：Cast string to float is not supported
  * 一开始百思不得其解，在没使用yaml文件之前，代码是不会报错的；故肯定是yaml文件出问题了
  * 一开始以为是数据加载出问题了，但是在详细阅读错误时看到(Adam/learning_rate)，就怀疑是学习率的问题，故进行了尝试
  * 首先不采用传递的参数，而是直接给数字0.001，不报错；其次将1e-3改成0.001，不报错；最后，将1e-03改成1.0e-3，不报错
  * 总结，若是直接写1e-03，yml会将其解析为字符串，故要写1.0e-3

在测试：训练，测试，测试数据集，代码均未报错，故先上传至github更新



> 修改制作tf-record文件数据代码

* 最好在创建tf_record的时候创建Matting，这下就节约了保存Matting矩阵的磁盘空间；创建一个保存一个，然后定好保存的数字。
  * 创建的tfrecord数量，和一个tfrecord中保存的数据条数保存到yml文件中
  * 创建Matting矩阵的图片是否要经过处理：比如减去均值
    * 在源代码中，是除以了255.

现在代码的思路是：首先规定好一共要创建的tfrecord个数及每个tfrecord中保存的数据个数，然后sess.run(matting)得到mat矩阵，然后再保存到tfrecord中



> 今日总结

* 将配置换成了yml文件，因为yml文件本身有限制，故将cmd和Yml文件共同使用
  * training共享
  * 部分参数cmd独享
* 修改制作tf-record数据的代码
  * 根据上述的思路修改代码



> 明日计划

* 测试数据生成代码
* 在机器学习平台或者实验室服务器跑数据（最好在机器学习平台，这样就不需要迁移数据）



### 2019/2/27

> 今日计划

* create_dataset()测试
  * 代码正常跑通
  * 检查速度是否提高
  * GPU/CPU/内存是否一直被占用无法释放，找到原因
* 将注意力机制放入风格迁移
  * 损失函数是否有问题，应该整体来算
  * 若是能成功运行并有结果，可视化在风格迁移过程中注意力的点



> create_dataset()测试

* 若是数据加载成功之后，可以将迭代的方式改变
* 现在面临的问题是，创建的矩阵的时候速度特别慢，电脑还会卡住，突然想到，之前把Matting矩阵保存到本地的原因是怕创建Matting浪费大量的时间。那我何不在代码运行时创建Matting矩阵，感觉速度还是很快的。故初步定制计划如下：
  * 首先修改代码，使得代码能够在运行的时候计算Matting矩阵
    * 检查出一个原以为是错误，在loss_affine计算中，matting矩阵是(原图/255)，故在affine loss中，生成的图也要/255。因为在生成器中，图片已经惩乘以127，的确要除以255
    * 一个问题：生成Matting矩阵的代码不是tensorflow编写的，故会报错
    * 通过compute_matting_matrix()方法解决
  * 其次，根据任意风格迁移代码的提示，修改加载Vgg19预训练模型的代码；这是为了**让数据不要在不同格式之间混编**



> 今日总结

* create_dataset()测试成功
* 修改代码，由提前创建matting矩阵到训练时创建matting矩阵



> 明日计划

* 写好测试代码，看一晚上的训练，若有好结果，训练代码



### 2019/2/28

> 今日计划

* 撰写测试代码并测试已保存的模型
  * 若正常输出，用实验室服务器跑
  * 若非正常输出，修改代码
* 下载两篇最新的论文，并阅读任意风格迁移的主要实现代码
* 考虑注意力机制加入风格迁移



> 测试代码

* 在查看测试代码后，发现测试代码根本不需要改变，故测试了模型
  * 2200轮不仅能输出模型的样子，而且所有的损失均在下降，但还未达到收敛



> 新论文+任意风格迁移

* 新论文已下载
  * 挑任意风格迁移作者的那一篇先看
* 对任意风格迁移存在误解
  * 每次训练并不是单独输入一张风格图，而是多张风格图参与训练
  * 已训练模型的效果图也不真实，像动画
* 考虑模仿他人的代码从头到尾写一遍真实风格迁移
  * 特别是加载预训练模型的地方



> 今日总结

* 测试了训练时计算matting矩阵的模型，能够跑通；然后在机器学习平台和本地电脑都在运行程序
* 再次了解任意风格迁移
* 阅读了部分风格人脸生成的论文



> 下一步计划

* 阅读注意力机制运用于GAN，看是否和soft-Attention有什么不同
* 复现任意风格迁移
  * 考虑加入注意力机制，看是否有不一样的效果
  * 若快速真实风格迁移有较好的效果，再加入仿射损失



### 2019/3/1

> 突然发现的问题

* **生成的图片也是需要做图片处理的，然后再进行损失计算**，而在我的代码中漏写了这一点，生成的图片也只能说看的过去



> 另一个疑惑的解答

* 参考的快速风格迁移代码通过tf.image.decode_jpeg()来解析图片，得到的图片格式是uint8
* 不管使用哪种方法加载预训练好的Vgg19模型，需要传入的图片type都必须是float中的一种，uint8是不可以传入的，故在自己写模型的过程中，因为这个问题，在测试模型这一块吃了很大的亏；此外，我使用的预训练模型传入的图片必须是bgr，故需要多次转换，也给我造成了极大的困扰
* 那为什么源代码没考虑图片格式的问题呢？
  * 是自己看代码不仔细，**作者在预处理图片的时候，使用tf.to_float()显示的转换了图片的格式**，所以再传入预训练模型才不会报错
* 既然输入预训练模型的图片格式是float，那么输出的图片格式也是float。但若想将图片保存到本地，图片的格式必须是uint8，那么作者是否处理了输出的图片格式呢？
  * 答案是肯定的，**tf.cast(generated, tf.uint8)**，作者又使用这句话将图片的格式转出来了

